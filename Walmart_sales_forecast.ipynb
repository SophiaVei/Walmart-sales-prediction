{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSZHKZcQV3xcIlBvyKquXH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary libraries and dataset"
      ],
      "metadata": {
        "id": "FFCQGRPPGnPH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD9wwbmafiIM"
      },
      "outputs": [],
      "source": [
        "# storing and anaysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from  IPython.display import display, HTML, display_html\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "# Time\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "# Facebook Prophet\n",
        "!pip install pystan~=2.14\n",
        "!pip install fbprophet\n",
        "\n",
        "# Stats tools\n",
        "from statsmodels.tsa.stattools import adfuller # Dickey-Fuller test\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose # Moving Average\n",
        "from statsmodels.tsa.stattools import acf, pacf # Autocorrelation and Partial Autocorrelation\n",
        "from statsmodels.tsa.arima_model import ARIMA # AutoRegressive Integrated Moving Average"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "walmart = pd.read_csv(io.BytesIO(uploaded['walmart_cleaned.csv']))"
      ],
      "metadata": {
        "id": "IX7hJqE5gZnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removes the NA's from the data\n",
        "for name in walmart.columns:\n",
        "  walmart[name] = walmart[name].fillna( value = 1e-10 )"
      ],
      "metadata": {
        "id": "1n9gMj3piT28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "ydaPDdX58C3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplots\n",
        "plt.figure(figsize=(30,10))\n",
        "count = 1\n",
        "for name in walmart.columns:\n",
        "  if name == 'Weekly_Sales'  or name == 'Temperature' or name == 'Fuel_Price' or name == 'Unemployment' or name == 'CPI' or name == 'MarkDown1' or name == 'MarkDown2' or name == 'MarkDown3' or name == 'MarkDown4' or name == 'MarkDown5':\n",
        "    plt.subplot(2,5,count)\n",
        "    count += 1\n",
        "    plot_me = walmart[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.boxplot(plot_me).set(title = name)\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "1e-AoGkrk2X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot With Color being the Stores\n",
        "plt.figure(figsize=(30,10))\n",
        "count = 1\n",
        "for name in walmart.columns:\n",
        "  if name == 'Weekly_Sales'  or name == 'Temperature' or name == 'Fuel_Price' or name == 'Unemployment' or name == 'CPI' or name == 'MarkDown1' or name == 'MarkDown2' or name == 'MarkDown3' or name == 'MarkDown4' or name == 'MarkDown5':\n",
        "    plt.subplot(2,5,count)\n",
        "    count += 1\n",
        "    plot_me = walmart[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.scatterplot(range(len(plot_me)), plot_me, hue = walmart['Store']).set(title = name)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k8_txp3Pk4rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot with Color being the store type\n",
        "plt.figure(figsize=(30,10))\n",
        "count = 1\n",
        "for name in walmart.columns:\n",
        "  if name == 'Weekly_Sales'  or name == 'Temperature' or name == 'Fuel_Price' or name == 'Unemployment' or name == 'CPI' or name == 'MarkDown1' or name == 'MarkDown2' or name == 'MarkDown3' or name == 'MarkDown4' or name == 'MarkDown5':\n",
        "    plt.subplot(2,5,count)\n",
        "    count += 1\n",
        "    plot_me = walmart[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.scatterplot(range(len(plot_me)), plot_me, hue = walmart['Type']).set(title = name)\n",
        "    plt.savefig('scatterpl with storetype.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RnOkHrwIlqka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average sales per department plot (all stores)\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.barplot(x='Dept',y='Weekly_Sales',data=walmart)\n",
        "plt.grid()\n",
        "plt.title('Average Sales per Department for all Stores', fontsize=18)\n",
        "plt.ylabel('Sales', fontsize=16)\n",
        "plt.xlabel('Department', fontsize=16)\n",
        "plt.savefig('avg_sales_dep.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nq4VGl3x_xWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average sales according to whether it's holiday or not (all stores)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(walmart['IsHoliday'].value_counts(),labels=['No Holiday','Holiday'],autopct='%0.2f%%')\n",
        "plt.title(\"Pie chart distribution for all Stores\",fontsize=14)\n",
        "plt.legend()\n",
        "plt.savefig('holiday_distribution.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y9Umby7CAMco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_sales = pd.DataFrame.mean(walmart['Weekly_Sales'])\n",
        "print(average_sales)"
      ],
      "metadata": {
        "id": "ZdbfzBGAmcH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_sales = pd.DataFrame.sum(walmart['Weekly_Sales'])\n",
        "num_of_stores = pd.DataFrame.max(walmart['Store'])\n",
        "print(sum_sales/(num_of_stores*140))"
      ],
      "metadata": {
        "id": "aQ8x3fcJmg6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing Store"
      ],
      "metadata": {
        "id": "sDeNuIDu_TjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep = ['Date',\t'Store',\t'Dept',\t'Weekly_Sales', 'Type',\t'Temperature', 'Fuel_Price',\t'CPI',\t'Unemployment']\n",
        "df = walmart[keep]\n",
        "\n",
        "for i in range(len(df['Weekly_Sales'])):\n",
        "  if df['Weekly_Sales'][i] >= 100000:\n",
        "    df['Weekly_Sales'][i] = pd.DataFrame.median(df['Weekly_Sales'])\n",
        "\n",
        "sns.boxplot(df['Weekly_Sales'])\n",
        "\n",
        "# Pulls out all the information about a single store (We are looking at Store 6)\n",
        "Store = walmart['Store'] == 6\n",
        "Store6 = walmart[Store]"
      ],
      "metadata": {
        "id": "lMdW2OBbmkuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average sales per department plot (store 6)\n",
        "plt.figure(figsize=(20,8))\n",
        "sns.barplot(x='Dept',y='Weekly_Sales',data=Store6)\n",
        "plt.grid()\n",
        "plt.title('Average Sales per Department for Store 6', fontsize=18)\n",
        "plt.ylabel('Sales', fontsize=16)\n",
        "plt.xlabel('Department', fontsize=16)\n",
        "plt.savefig('avg_sales_dep_store6.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HdK6Xwx6BcUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average sales according to whether it's holiday or not (store 6)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(Store6['IsHoliday'].value_counts(),labels=['No Holiday','Holiday'],autopct='%0.2f%%')\n",
        "plt.title(\"Pie chart distribution for Store 6\",fontsize=14)\n",
        "plt.legend()\n",
        "#plt.savefig('holiday_distribution.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LsKX1LIZBo2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing Department(s)"
      ],
      "metadata": {
        "id": "9hgHOuXTX3pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change number of department below to check for specific department. We decided to check departments 5,6,92 of Store 6,\n",
        "# since we want to check forecasts for a medium, small and large sales department accordingly\n",
        "\n",
        "################### Pulls out all the information about a single department (We are looking at Department 5) ###################\n",
        "#Department = Store6['Dept'] == 5\n",
        "#Department5 = Store6[Department]\n",
        "#Store6 = Department5\n",
        "#df = Store6\n",
        "\n",
        "################### Pulls out all the information about a single department (We are looking at Department 6) ###################\n",
        "#Department = Store6['Dept'] == 6\n",
        "#Department6 = Store6[Department]\n",
        "#Store6 = Department6\n",
        "#df = Store6\n",
        "\n",
        "################### Pulls out all the information about a single department (We are looking at Department 92) ###################\n",
        "Department = Store6['Dept'] == 92\n",
        "Department92 = Store6[Department]\n",
        "Store6 = Department92\n",
        "df = Store6"
      ],
      "metadata": {
        "id": "KLfDNrB2BDDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#average sales according to whether it's holiday or not (department 5,6 or 92, according to which one we are checking)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(df['IsHoliday'].value_counts(),labels=['No Holiday','Holiday'],autopct='%0.2f%%')\n",
        "plt.title(\"Pie chart distribution for Department\",fontsize=14)\n",
        "plt.legend()\n",
        "#plt.savefig('holiday_distribution.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFcZowyfB8ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot with Color being the date\n",
        "plt.figure(figsize=(30,10))\n",
        "count = 1\n",
        "\n",
        "for name in Store6.columns:\n",
        "  if name == 'Weekly_Sales'  or name == 'Temperature' or name == 'Fuel_Price' or name == 'Unemployment' or name == 'CPI' or name == 'MarkDown1' or name == 'MarkDown2' or name == 'MarkDown3' or name == 'MarkDown4' or name == 'MarkDown5':\n",
        "    plt.subplot(2,5,count)\n",
        "    count += 1\n",
        "    plot_me = Store6[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.scatterplot(range(len(plot_me)), plot_me, hue = Store6['Date'], legend=False).set(title = name)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zAYlDtPVm-hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "count = 1\n",
        "\n",
        "for name in Store6.columns:\n",
        "  if name == 'Weekly_Sales':\n",
        "    count += 1\n",
        "    plot_me = Store6[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.scatterplot(range(len(plot_me)), plot_me, hue = Store6['Date'], legend=False).set(title = name)\n",
        "    plt.savefig('weeklysalesdep92.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bfVVFx-1nMJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "count = 1\n",
        "\n",
        "for name in Store6.columns:\n",
        "  if name == 'Weekly_Sales':\n",
        "    count += 1\n",
        "    plot_me = Store6[name]\n",
        "    plot_me = plot_me.to_numpy()\n",
        "    plot_me = plot_me.astype(float)\n",
        "    sns.lineplot(range(len(plot_me)), plot_me, legend= False).set(title = name)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzpSiohKnVez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Formating the Data for Time Series analysis"
      ],
      "metadata": {
        "id": "_711tUQZneXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns = {'Date':'ds', 'Weekly_Sales':'ws'})\n",
        "keep2 = ['ds', 'ws']\n",
        "df_example = df[keep2]"
      ],
      "metadata": {
        "id": "F8r-z5Pgndug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualization For Weekly Sales"
      ],
      "metadata": {
        "id": "KtRE5FDbnoyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(1,1)\n",
        "ax.plot(df_example['ws'])"
      ],
      "metadata": {
        "id": "7gBbhpH4nqxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_stationarity(df, ts):\n",
        "    \"\"\"\n",
        "    Test stationarity using moving average statistics and Dickey-Fuller test\n",
        "    Source: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
        "    \"\"\"\n",
        "    \n",
        "    # Determing rolling statistics\n",
        "    rolmean = df[ts].rolling(window = 12, center = False).mean()\n",
        "    rolstd = df[ts].rolling(window = 12, center = False).std()\n",
        "    \n",
        "    # Plot rolling statistics:\n",
        "    orig = plt.plot(df[ts], \n",
        "                    color = 'blue', \n",
        "                    label = 'Original')\n",
        "    mean = plt.plot(rolmean, \n",
        "                    color = 'red', \n",
        "                    label = 'Rolling Mean')\n",
        "    std = plt.plot(rolstd, \n",
        "                   color = 'black', \n",
        "                   label = 'Rolling Std')\n",
        "    plt.legend(loc = 'best')\n",
        "    plt.title('Rolling Mean & Standard Deviation for %s' %(ts))\n",
        "    plt.xticks(rotation = 45)\n",
        "    plt.show(block = False)\n",
        "    \n",
        "    plt.close()\n",
        "    # Plots the Data wit the Rolling Mean and Rolling Std\n",
        "test_stationarity(df = df_example, ts ='ws') # Rolling mean and Rolling Std appear to be stationary\n"
      ],
      "metadata": {
        "id": "2_u0xJBZn6DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the Data wit the Rolling Mean and Rolling Std\n",
        "test_stationarity(df = df_example, ts ='ws') # Rolling mean and Rolling Std appear to be stationary"
      ],
      "metadata": {
        "id": "wcRoSeZtoGRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transform(df, ts, ts_transform):\n",
        "  f, ax = plt.subplots(1, 1)\n",
        "  ax.plot(df[ts])\n",
        "  ax.plot(df[ts_transform], color = 'red')"
      ],
      "metadata": {
        "id": "q3w-jikHoIrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_example['ws_log'] = df_example['ws'].apply(lambda x: np.log(x))"
      ],
      "metadata": {
        "id": "d7yRfflHoKoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_transform(df_example, 'ws', 'ws_log')"
      ],
      "metadata": {
        "id": "pBiObCyRoMuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_example['ws_log_moving_avg'] = df_example['ws_log'].rolling(window =7, center = False).mean()"
      ],
      "metadata": {
        "id": "I4IdF7FtoPFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_example['ws_moving_avg']      = df_example['ws'].rolling(window = 7, center = False).mean()\n",
        "df_example['ws_log_diff']        = df_example['ws_log'].diff()\n",
        "df_example['ws_moving_avg_diff'] = df_example['ws'] - df_example['ws_moving_avg']\n",
        "df_example['ws_ewma']            = df_example['ws'].ewm(halflife = 7, ignore_na = False, min_periods = 0, adjust = True).mean()\n",
        "df_example['ws_log_ewma']        = df_example['ws_log'].ewm(halflife =7, ignore_na =False,min_periods=0, adjust=True).mean()\n",
        "df_example['ws_log_ewma_diff']   = df_example['ws_log'] - df_example['ws_log_ewma']\n",
        "\n",
        "\n",
        "df_example_trans = df_example.dropna()"
      ],
      "metadata": {
        "id": "hpRr_mppoSIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_example_trans['ws_log_ewma']=df_example_trans['ws_log'].ewm(halflife =7, ignore_na =False,min_periods=0, adjust=True).mean()\n",
        "df_example_trans['ws_log_ewma_diff']=df_example_trans['ws_log']-df_example_trans['ws_log_ewma']"
      ],
      "metadata": {
        "id": "jhtmnNuOoUkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minus the Moving Average\n",
        "plot_transform(df_example, 'ws', 'ws_moving_avg_diff')"
      ],
      "metadata": {
        "id": "-5J0LABpoXMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expontential Weighted Moving Average\n",
        "plot_transform(df_example, 'ws', 'ws_ewma')"
      ],
      "metadata": {
        "id": "MHCBYk0hoZO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Difference in the Log of the Expontential Weighted Moving Average\n",
        "test_stationarity(df_example, 'ws_log_ewma_diff')"
      ],
      "metadata": {
        "id": "5itCDeRQobra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Difference in the Log of the Expontential Weighted Moving Average for the Transformation\n",
        "test_stationarity(df_example_trans, 'ws_log_ewma_diff')"
      ],
      "metadata": {
        "id": "Bohp3ML0obl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decomposition Analysis"
      ],
      "metadata": {
        "id": "y2gh-kKFqoER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decomposition(df, ts, trend, seasonal, residual):\n",
        "    \n",
        "  f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (15, 5), sharex = True)\n",
        "\n",
        "  ax1.plot(df[ts], label = 'Original')\n",
        "  ax1.legend(loc = 'best')\n",
        "  ax1.tick_params(axis = 'x', rotation = 45)\n",
        "\n",
        "  ax2.plot(df[trend], label = 'Trend')\n",
        "  ax2.legend(loc = 'best')\n",
        "  ax2.tick_params(axis = 'x', rotation = 45)\n",
        "\n",
        "  ax3.plot(df[seasonal],label = 'Seasonality')\n",
        "  ax3.legend(loc = 'best')\n",
        "  ax3.tick_params(axis = 'x', rotation = 45)\n",
        "\n",
        "  ax4.plot(df[residual], label = 'Residuals')\n",
        "  ax4.legend(loc = 'best')\n",
        "  ax4.tick_params(axis = 'x', rotation = 45)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # plt.subtitle('Signal Decomposition of %s' %(ts), x = 0.5, y = 1.05, fontsize = 18)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "froFbgm6pH9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decomposition = seasonal_decompose(df_example_trans['ws_log'], freq = 52)\n",
        "\n",
        "df_example_trans.loc[:,'trend']    = decomposition.trend\n",
        "df_example_trans.loc[:,'seasonal'] = decomposition.seasonal\n",
        "df_example_trans.loc[:,'residual'] = decomposition.resid\n",
        "\n",
        "plot_decomposition(df = df_example_trans, ts= 'ws_log', trend='trend', seasonal='seasonal', residual='residual')\n",
        "\n",
        "test_stationarity(df_example_trans.dropna(), ts='residual')"
      ],
      "metadata": {
        "id": "E8WX0GyTqy5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Arima"
      ],
      "metadata": {
        "id": "PzE9RjUAq6QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_arima(df,ts,p,d,q):\n",
        "  \n",
        "  model=ARIMA(df[ts], order=(p,d,q))\n",
        "  results_arima=model.fit(disp=-1)\n",
        "\n",
        "  len_results = len(results_arima.fittedvalues)\n",
        "  ts_modified = df[ts][-len_results:]\n",
        "\n",
        "  rss  = sum((results_arima.fittedvalues - ts_modified)**2)\n",
        "  rmse = np.sqrt(rss/ len(df[ts]))\n",
        "\n",
        "  plt.figure(figsize=(30,15))\n",
        "  plt.plot(df[ts])\n",
        "  plt.plot(results_arima.fittedvalues, color='red')\n",
        "  plt.savefig('arima1.png')\n",
        "  plt.show()\n",
        "  plt.savefig('arima.png')\n",
        "  return results_arima\n",
        "     \n",
        "\n",
        "model_AR = run_arima(df= df_example_trans, ts='ws_log_diff',p=2,d=0,q=2)"
      ],
      "metadata": {
        "id": "LFlu6Yfeq51z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Facebook Prophet"
      ],
      "metadata": {
        "id": "yWzqyak_rGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def days_between(d1, d2):\n",
        "  \"\"\" return the number of days between two different days \"\"\"\n",
        "  d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
        "  d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
        "\n",
        "  return abs((d2-d1).days+1)"
      ],
      "metadata": {
        "id": "vv9iHzb2rHF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inputs for query\n",
        "\n",
        "date_column = 'ds'\n",
        "metric_column = 'ws'\n",
        "table = df_example\n",
        "start_training_date = '2010-02-05'\n",
        "end_training_date = '2012-10-26'\n",
        "start_forecasting_date = '2010-02-05'\n",
        "end_forecasting_date = '2012-01-11'\n",
        "year_to_estimate = '2010'\n",
        "\n",
        "# Inputs for forecasting\n",
        "\n",
        "# future_num_points\n",
        "# If doing different time intervals, change future_num_points\n",
        "future_num_points = 7\n",
        "\n",
        "cap = None # 2e6\n",
        "\n",
        "# growth: default = 'linear'\n",
        "# Can also choose 'logistic'\n",
        "growth = 'linear'\n",
        "\n",
        "# n_changepoints: default = 25, uniformly placed in first 80% of time series\n",
        "n_changepoints = 25 \n",
        "\n",
        "# changepoint_prior_scale: default = 0.04\n",
        "# Increasing it will make the trend more flexible\n",
        "changepoint_prior_scale = 0.06\n",
        "\n",
        "# changpoints: example = ['2016-01-01']\n",
        "changepoints = None \n",
        "\n",
        "# holidays_prior_scale: default = 10\n",
        "\n",
        "holidays_prior_scale = 10 \n",
        "\n",
        "# interval_width: default = 0.8\n",
        "interval_width = 0.8\n",
        "mcmc_samples = 0\n",
        "\n",
        "holidays = None\n",
        "\n",
        "daily_seasonality = True"
      ],
      "metadata": {
        "id": "ONRK_wWGrQCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prophet = df_example_trans[['ds','ws']]\n",
        "df_prophet = df_prophet.reset_index()\n",
        "df_prophet = df_prophet.rename(columns = {'ds':'ds','ws':'y'})\n",
        "df_prophet['ds']=pd.to_datetime(df_prophet['ds'])\n",
        "df_prophet['y']=pd.to_numeric(df_prophet['y'], errors='ignore')"
      ],
      "metadata": {
        "id": "1PO9zPkHs58X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fbprophet import Prophet\n",
        "from pandas import DateOffset"
      ],
      "metadata": {
        "id": "OrPRT5vYt8h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weekly_forecast(df, holidays, growth, n_changepoints=25, holidays_prior_scale=10, changepoint_prior_scale=0.05,\n",
        "                    changepoints=None, interval_width=0.8, mcmc_samples=1, future_num_points=7,\n",
        "                    daily_seasonality=True):\n",
        "    df_c = df.copy()\n",
        "    df_c['ds'] = df_c['ds'].dt.to_period(\"W\").apply(lambda x: x.start_time)\n",
        "    df_c = df_c.groupby('ds').sum().reset_index()\n",
        "    m = Prophet(growth=growth,\n",
        "                n_changepoints=n_changepoints,\n",
        "                changepoint_prior_scale=changepoint_prior_scale,\n",
        "                changepoints=changepoints,\n",
        "                holidays=holidays,\n",
        "                holidays_prior_scale=holidays_prior_scale,\n",
        "                interval_width=interval_width,\n",
        "                mcmc_samples=mcmc_samples,\n",
        "                daily_seasonality=False)\n",
        "    m.fit(df_c)\n",
        "    future = m.make_future_dataframe(periods=future_num_points)\n",
        "    future['ds'].iloc[0] = start_forecasting_date\n",
        "    for i in range(1, len(future)):\n",
        "      future['ds'].iloc[i] = future['ds'].iloc[i-1] + DateOffset(days=7)\n",
        "\n",
        "    forecst = m.predict(future)\n",
        "\n",
        "    m.plot(forecst)\n",
        "    m.plot_components(forecst)\n",
        "\n",
        "    return forecst\n",
        "\n",
        "\n",
        "forecst = weekly_forecast(df_prophet, holidays, growth, n_changepoints, holidays_prior_scale,\n",
        "                          changepoint_prior_scale, changepoints, interval_width, mcmc_samples, future_num_points)"
      ],
      "metadata": {
        "id": "_YROdxfkHXGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(forecst)"
      ],
      "metadata": {
        "id": "ov0GT9XVHnjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#store forecast results of department 5\n",
        "#forecst.to_csv(\"forecast_results_store6_dep5.csv\", index=False)\n",
        "\n",
        "#store forecast results of department 6\n",
        "#forecst.to_csv(\"forecast_results_store6_dep6.csv\", index=False)\n",
        "\n",
        "#store forecast results of department 92\n",
        "forecst.to_csv(\"forecast_results_store6_dep92.csv\", index=False)"
      ],
      "metadata": {
        "id": "SMFg6K03H4Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculate Metrics (from Prophet)"
      ],
      "metadata": {
        "id": "lqnF-xDvurmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(y_true, y_pred):\n",
        "    \"\"\" Calculate mean absolute percentage error (MAPE)\"\"\"\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def calculate_mpe(y_true, y_pred):\n",
        "    \"\"\" Calculate mean percentage error (MPE)\"\"\"\n",
        "    return np.mean((y_true - y_pred) / y_true) * 100\n",
        "\n",
        "def calculate_mae(y_true, y_pred):\n",
        "    \"\"\" Calculate mean absolute error (MAE)\"\"\"\n",
        "    return np.mean(np.abs(y_true - y_pred)) * 100\n",
        "\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    \"\"\" Calculate root mean square error (RMSE)\"\"\"\n",
        "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "def print_error_metrics(y_true, y_pred):\n",
        "    print('MAPE: %f'%calculate_mape(y_true, y_pred))\n",
        "    print('MPE: %f'%calculate_mpe(y_true, y_pred))\n",
        "    print('MAE: %f'%calculate_mae(y_true, y_pred))\n",
        "    print('RMSE: %f'%calculate_rmse(y_true, y_pred))\n",
        "    return"
      ],
      "metadata": {
        "id": "ob7DnG6zus4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_error_metrics(y_true = df_prophet['y'], y_pred = forecst['yhat'])"
      ],
      "metadata": {
        "id": "HK_Ww6aAux1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}